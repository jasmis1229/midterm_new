{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuiN4kHRKxiVX5oEiwBhG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasmis1229/midterm_new/blob/main/%ED%8A%B8%EB%A0%8C%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 실험 초기화\n",
        "\n",
        "# 1. 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# 2. 데이터 불러오기\n",
        "df = pd.read_csv('/content/신조어_스타일_패턴_완성본_UTF8SIG.csv')  # 파일명은 환경에 맞게 수정"
      ],
      "metadata": {
        "id": "Wd1t0ZUu6EXC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 데이터 정제\n",
        "\n",
        "# 신조어 앞 번호 제거 함수\n",
        "def clean_word(word):\n",
        "    word = str(word)\n",
        "    return re.sub(r'^\\d+\\.', '', word).strip()\n",
        "\n",
        "# 클린 신조어 컬럼 생성\n",
        "df['클린 신조어'] = df['신조어'].apply(clean_word)"
      ],
      "metadata": {
        "id": "yqI1uxJtPJlU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 설명 토크나이징\n",
        "\n",
        "# 간단 토크나이징 함수\n",
        "def simple_tokenize(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", str(text))  # 특수문자 제거\n",
        "    tokens = text.strip().split()\n",
        "    tokens = [token for token in tokens if len(token) > 1]  # 한 글자 제거\n",
        "    return tokens\n",
        "\n",
        "# 설명 토크나이징 적용\n",
        "descriptions = df['설명'].tolist()\n",
        "tokenized_descriptions = [simple_tokenize(desc) for desc in descriptions]"
      ],
      "metadata": {
        "id": "lFWro2mUPbUc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 어휘 사전 구축\n",
        "\n",
        "vocab = set()\n",
        "for tokens in tokenized_descriptions:\n",
        "    vocab.update(tokens)\n",
        "\n",
        "# 단어 ↔ 인덱스 매핑\n",
        "vocab = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "TVTD5BY_Puyt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 학습 데이터셋 생성\n",
        "\n",
        "window_size = 2\n",
        "context_center_pairs = []\n",
        "\n",
        "for tokens in tokenized_descriptions:\n",
        "    for idx, center_word in enumerate(tokens):\n",
        "        context = []\n",
        "        for i in range(idx - window_size, idx + window_size + 1):\n",
        "            if i != idx and 0 <= i < len(tokens):\n",
        "                context.append(vocab[tokens[i]])\n",
        "        if context:\n",
        "            context_center_pairs.append((context, vocab[center_word]))"
      ],
      "metadata": {
        "id": "qNnXiZirQAt0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW Dataset 클래스 정의\n",
        "\n",
        "class CBOWDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context, center = self.data[idx]\n",
        "        return torch.tensor(context), torch.tensor(center)\n",
        "\n",
        "# DataLoader 생성\n",
        "dataset = CBOWDataset(context_center_pairs)\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=lambda batch: list(zip(*batch)))"
      ],
      "metadata": {
        "id": "n_HCqFoaQQgc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 모델 클래스 정의\n",
        "\n",
        "class CBOWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100):\n",
        "        super(CBOWModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, contexts):\n",
        "        embeds = []\n",
        "        for context in contexts:\n",
        "            embed = self.embeddings(context)\n",
        "            embeds.append(embed.mean(dim=0))\n",
        "        embeds = torch.stack(embeds)\n",
        "        out = self.linear(embeds)\n",
        "        return out"
      ],
      "metadata": {
        "id": "SKDHKfjxQgG6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 모델 초기화\n",
        "\n",
        "model = CBOWModel(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "HGwlT_bvQwG6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 학습 루프\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for contexts, centers in train_loader:\n",
        "        outputs = model(contexts)\n",
        "        loss = criterion(outputs, torch.tensor(centers))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jTFVCgLRIJq",
        "outputId": "8c866f54-fee4-4281-f6bc-606008287200"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 102.8183\n",
            "Epoch [2/20], Loss: 99.6956\n",
            "Epoch [3/20], Loss: 96.8455\n",
            "Epoch [4/20], Loss: 94.1754\n",
            "Epoch [5/20], Loss: 91.3577\n",
            "Epoch [6/20], Loss: 88.4945\n",
            "Epoch [7/20], Loss: 85.8633\n",
            "Epoch [8/20], Loss: 83.0899\n",
            "Epoch [9/20], Loss: 80.3510\n",
            "Epoch [10/20], Loss: 77.5348\n",
            "Epoch [11/20], Loss: 74.8449\n",
            "Epoch [12/20], Loss: 72.0077\n",
            "Epoch [13/20], Loss: 69.2950\n",
            "Epoch [14/20], Loss: 66.4486\n",
            "Epoch [15/20], Loss: 63.9486\n",
            "Epoch [16/20], Loss: 61.0662\n",
            "Epoch [17/20], Loss: 58.3412\n",
            "Epoch [18/20], Loss: 55.7727\n",
            "Epoch [19/20], Loss: 53.1345\n",
            "Epoch [20/20], Loss: 50.5563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **여기까지가 CBOW 학습**"
      ],
      "metadata": {
        "id": "fBDGQqFCRb-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 문맥 예측 테스트\n",
        "\n",
        "model.eval()\n",
        "\n",
        "random_idx = random.randint(0, len(context_center_pairs) - 1)\n",
        "random_context, true_center = context_center_pairs[random_idx]\n",
        "\n",
        "context_tensor = torch.tensor([random_context])\n",
        "predicted_logits = model(context_tensor)\n",
        "predicted_probs = F.softmax(predicted_logits, dim=1)\n",
        "top5 = torch.topk(predicted_probs, 5)\n",
        "\n",
        "print(\"\\n[CBOW 예측 테스트 결과]\")\n",
        "print(f\"문맥(Context): {[idx_to_word[idx] for idx in random_context]}\")\n",
        "print(f\"정답(Center): {idx_to_word[true_center]}\")\n",
        "\n",
        "print(\"\\nTop-5 예측 단어:\")\n",
        "for i in range(5):\n",
        "    idx = top5.indices[0][i].item()\n",
        "    prob = top5.values[0][i].item()\n",
        "    print(f\"{i+1}. {idx_to_word[idx]} (확률: {prob:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcyYJdduR5bb",
        "outputId": "5f9f4d3a-4370-4cec-b790-e672b95803e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CBOW 예측 테스트 결과]\n",
            "문맥(Context): ['여행을', '가든', '하든', '일않하고']\n",
            "정답(Center): 뭔일을\n",
            "\n",
            "Top-5 예측 단어:\n",
            "1. 뭔일을 (확률: 0.0135)\n",
            "2. 손가락은 (확률: 0.0085)\n",
            "3. 하든 (확률: 0.0037)\n",
            "4. 않도록 (확률: 0.0029)\n",
            "5. 게시물 (확률: 0.0026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 예측 최적화\n",
        "\n",
        "model.eval()\n",
        "\n",
        "random_idx = random.randint(0, len(context_center_pairs) - 1)\n",
        "random_context, true_center = context_center_pairs[random_idx]\n",
        "\n",
        "with torch.no_grad():\n",
        "    context_tensor = torch.tensor([random_context])\n",
        "    predicted_logits = model(context_tensor)\n",
        "    predicted_probs = F.softmax(predicted_logits, dim=1)\n",
        "    top5 = torch.topk(predicted_probs, 5)\n",
        "\n",
        "print(\"\\n[CBOW 예측 테스트 결과 개선]\")\n",
        "print(f\"문맥(Context): {[idx_to_word[idx] for idx in random_context]}\")\n",
        "print(f\"정답(Center): {idx_to_word[true_center]}\")\n",
        "\n",
        "print(\"\\nTop-5 예측 단어:\")\n",
        "for i in range(5):\n",
        "    idx = top5.indices[0][i].item()\n",
        "    prob = top5.values[0][i].item()\n",
        "    print(f\"{i+1}. {idx_to_word[idx]} (확률: {prob:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr5yxnxwSVsc",
        "outputId": "29a0fdb6-dfd7-4d22-890b-c6d1ea4b7624"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CBOW 예측 테스트 결과 개선]\n",
            "문맥(Context): ['싶어서', '눈알이']\n",
            "정답(Center): 꼿힐때\n",
            "\n",
            "Top-5 예측 단어:\n",
            "1. 꼿힐때 (확률: 0.0488)\n",
            "2. 물건 (확률: 0.0101)\n",
            "3. 사고 (확률: 0.0075)\n",
            "4. 뜸들어 (확률: 0.0072)\n",
            "5. 눈알이 (확률: 0.0072)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CBOW 스타일 기반 미래 신조어 생성\n",
        "\n",
        "sample_rows = df.sample(3, random_state=random.randint(0,10000))\n",
        "\n",
        "print(\"\\n[미래 신조어 스타일 예측 및 생성]\")\n",
        "\n",
        "selected_words = []\n",
        "combined_styles = set()\n",
        "\n",
        "for idx, row in sample_rows.iterrows():\n",
        "    word = row['클린 신조어']\n",
        "    style = row['스타일 패턴']\n",
        "    print(f\"기존 신조어: {word}\")\n",
        "    print(f\"스타일 패턴: {style}\\n\")\n",
        "    selected_words.append(word)\n",
        "    combined_styles.update(style.split(', '))\n",
        "\n",
        "def safe_pick(word, pos):\n",
        "    if len(word) == 1:\n",
        "        return word\n",
        "    if pos == 'start':\n",
        "        return word[0]\n",
        "    elif pos == 'middle':\n",
        "        return word[len(word)//2]\n",
        "    elif pos == 'end':\n",
        "        return word[-1]\n",
        "    else:\n",
        "        return random.choice(word)\n",
        "\n",
        "new_created_word = (\n",
        "    safe_pick(selected_words[0], 'start') +\n",
        "    safe_pick(selected_words[1], 'middle') +\n",
        "    safe_pick(selected_words[2], 'end')\n",
        ")\n",
        "\n",
        "print(f\"👉 생성된 미래 신조어: {new_created_word}\")\n",
        "print(f\"👉 예상되는 스타일 패턴: {', '.join(list(combined_styles))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFgcHN-qSomZ",
        "outputId": "362caf0e-6d9e-40ec-b2d0-8d11a0855df0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[미래 신조어 스타일 예측 및 생성]\n",
            "기존 신조어: 비담\n",
            "스타일 패턴: 리듬감\n",
            "\n",
            "기존 신조어: 자라족\n",
            "스타일 패턴: 리듬감+감정성\n",
            "\n",
            "기존 신조어: 선리후감\n",
            "스타일 패턴: 리듬감+감정성\n",
            "\n",
            "👉 생성된 미래 신조어: 비라감\n",
            "👉 예상되는 스타일 패턴: 리듬감+감정성, 리듬감\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 첫 시도 코드"
      ],
      "metadata": {
        "id": "4nsOiz4OToNh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlIlPx1uF5P-",
        "outputId": "2757b691-e5ea-48d2-f857-10acf4954834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 102.7254\n",
            "Epoch [2/20], Loss: 99.6482\n",
            "Epoch [3/20], Loss: 96.8595\n",
            "Epoch [4/20], Loss: 94.0647\n",
            "Epoch [5/20], Loss: 91.2805\n",
            "Epoch [6/20], Loss: 88.6131\n",
            "Epoch [7/20], Loss: 85.7855\n",
            "Epoch [8/20], Loss: 83.0773\n",
            "Epoch [9/20], Loss: 80.2598\n",
            "Epoch [10/20], Loss: 77.5700\n",
            "Epoch [11/20], Loss: 74.9174\n",
            "Epoch [12/20], Loss: 72.1179\n",
            "Epoch [13/20], Loss: 69.3065\n",
            "Epoch [14/20], Loss: 66.5300\n",
            "Epoch [15/20], Loss: 63.8406\n",
            "Epoch [16/20], Loss: 61.1367\n",
            "Epoch [17/20], Loss: 58.4678\n",
            "Epoch [18/20], Loss: 55.9640\n",
            "Epoch [19/20], Loss: 53.1117\n",
            "Epoch [20/20], Loss: 50.5708\n"
          ]
        }
      ],
      "source": [
        "# ✅ Colab용 CBOW 미래 신조어 스타일 예측\n",
        "\n",
        "# 1. 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 2. 데이터 불러오기 (Colab에 업로드한 파일 직접 경로로 읽기)\n",
        "df = pd.read_csv('/content/신조어_데이터셋_최종본.csv')\n",
        "\n",
        "# 3. 간단 토크나이징 함수\n",
        "def simple_tokenize(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", str(text))  # 특수문자 제거\n",
        "    tokens = text.strip().split()\n",
        "    tokens = [token for token in tokens if len(token) > 1]  # 한 글자 제거\n",
        "    return tokens\n",
        "\n",
        "# 4. 데이터 전처리: 설명을 토크나이징\n",
        "descriptions = df['설명'].tolist()\n",
        "tokenized_descriptions = [simple_tokenize(desc) for desc in descriptions]\n",
        "\n",
        "# 5. 어휘 사전 구축\n",
        "vocab = set()\n",
        "for tokens in tokenized_descriptions:\n",
        "    vocab.update(tokens)\n",
        "vocab = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 6. CBOW 학습용 데이터셋 생성\n",
        "window_size = 2\n",
        "context_center_pairs = []\n",
        "\n",
        "for tokens in tokenized_descriptions:\n",
        "    for idx, center_word in enumerate(tokens):\n",
        "        context = []\n",
        "        for i in range(idx - window_size, idx + window_size + 1):\n",
        "            if i != idx and 0 <= i < len(tokens):\n",
        "                context.append(vocab[tokens[i]])\n",
        "        if context:\n",
        "            context_center_pairs.append((context, vocab[center_word]))\n",
        "\n",
        "# 7. Dataset 클래스 정의\n",
        "class CBOWDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context, center = self.data[idx]\n",
        "        return torch.tensor(context), torch.tensor(center)\n",
        "\n",
        "# 8. DataLoader 생성\n",
        "dataset = CBOWDataset(context_center_pairs)\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=lambda batch: list(zip(*batch)))\n",
        "\n",
        "# 9. CBOW 모델 정의\n",
        "class CBOWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100):\n",
        "        super(CBOWModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, contexts):\n",
        "        embeds = []\n",
        "        for context in contexts:\n",
        "            embed = self.embeddings(context)\n",
        "            embeds.append(embed.mean(dim=0))\n",
        "        embeds = torch.stack(embeds)\n",
        "        out = self.linear(embeds)\n",
        "        return out\n",
        "\n",
        "# 10. 모델 초기화\n",
        "model = CBOWModel(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 11. 학습 루프\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for contexts, centers in train_loader:\n",
        "        outputs = model(contexts)\n",
        "        loss = criterion(outputs, torch.tensor(centers))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "\n",
        "# 12. 학습 완료!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 개선"
      ],
      "metadata": {
        "id": "InfP-QdoT64G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Colab용 CBOW 미래 신조어 스타일 예측 기본 코드 (예측 테스트 추가)\n",
        "\n",
        "# 1. 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import re\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 2. 데이터 불러오기 (Colab에 업로드한 파일 직접 경로로 읽기)\n",
        "df = pd.read_csv('/content/신조어_데이터셋_최종본_랜덤라벨링.csv')\n",
        "\n",
        "# 3. 간단 토크나이징 함수\n",
        "def simple_tokenize(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", str(text))  # 특수문자 제거\n",
        "    tokens = text.strip().split()\n",
        "    tokens = [token for token in tokens if len(token) > 1]  # 한 글자 제거\n",
        "    return tokens\n",
        "\n",
        "# 4. 데이터 전처리: 설명을 토크나이징\n",
        "descriptions = df['설명'].tolist()\n",
        "tokenized_descriptions = [simple_tokenize(desc) for desc in descriptions]\n",
        "\n",
        "# 5. 어휘 사전 구축\n",
        "vocab = set()\n",
        "for tokens in tokenized_descriptions:\n",
        "    vocab.update(tokens)\n",
        "vocab = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 6. CBOW 학습용 데이터셋 생성\n",
        "window_size = 2\n",
        "context_center_pairs = []\n",
        "\n",
        "for tokens in tokenized_descriptions:\n",
        "    for idx, center_word in enumerate(tokens):\n",
        "        context = []\n",
        "        for i in range(idx - window_size, idx + window_size + 1):\n",
        "            if i != idx and 0 <= i < len(tokens):\n",
        "                context.append(vocab[tokens[i]])\n",
        "        if context:\n",
        "            context_center_pairs.append((context, vocab[center_word]))\n",
        "\n",
        "# 7. Dataset 클래스 정의\n",
        "class CBOWDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context, center = self.data[idx]\n",
        "        return torch.tensor(context), torch.tensor(center)\n",
        "\n",
        "# 8. DataLoader 생성\n",
        "dataset = CBOWDataset(context_center_pairs)\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=lambda batch: list(zip(*batch)))\n",
        "\n",
        "# 9. CBOW 모델 정의\n",
        "class CBOWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100):\n",
        "        super(CBOWModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, contexts):\n",
        "        embeds = []\n",
        "        for context in contexts:\n",
        "            embed = self.embeddings(context)\n",
        "            embeds.append(embed.mean(dim=0))\n",
        "        embeds = torch.stack(embeds)\n",
        "        out = self.linear(embeds)\n",
        "        return out\n",
        "\n",
        "# 10. 모델 초기화\n",
        "model = CBOWModel(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 11. 학습 루프\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for contexts, centers in train_loader:\n",
        "        outputs = model(contexts)\n",
        "        loss = criterion(outputs, torch.tensor(centers))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "\n",
        "# 12. 예측 테스트\n",
        "model.eval()\n",
        "\n",
        "# 랜덤 context-center 하나 뽑기\n",
        "random_idx = random.randint(0, len(context_center_pairs) - 1)\n",
        "random_context, true_center = context_center_pairs[random_idx]\n",
        "\n",
        "# 예측 수행\n",
        "context_tensor = torch.tensor([random_context])\n",
        "predicted_logits = model(context_tensor)\n",
        "predicted_probs = F.softmax(predicted_logits, dim=1)\n",
        "top5 = torch.topk(predicted_probs, 5)\n",
        "\n",
        "print(\"\\n[예측 테스트 결과]\")\n",
        "print(f\"문맥(Context): {[idx_to_word[idx] for idx in random_context]}\")\n",
        "print(f\"정답(Center): {idx_to_word[true_center]}\")\n",
        "\n",
        "print(\"\\nTop-5 예측 단어:\")\n",
        "for i in range(5):\n",
        "    idx = top5.indices[0][i].item()\n",
        "    prob = top5.values[0][i].item()\n",
        "    print(f\"{i+1}. {idx_to_word[idx]} (확률: {prob:.4f})\")\n",
        "\n",
        "# 13. 학습 및 테스트 완료!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGDGHqzFJ6eY",
        "outputId": "698aea9e-1fbd-4ca4-8773-d73424078025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 102.6710\n",
            "Epoch [2/20], Loss: 99.6654\n",
            "Epoch [3/20], Loss: 96.8958\n",
            "Epoch [4/20], Loss: 94.1144\n",
            "Epoch [5/20], Loss: 91.4124\n",
            "Epoch [6/20], Loss: 88.6321\n",
            "Epoch [7/20], Loss: 85.8246\n",
            "Epoch [8/20], Loss: 83.1512\n",
            "Epoch [9/20], Loss: 80.4493\n",
            "Epoch [10/20], Loss: 77.7554\n",
            "Epoch [11/20], Loss: 74.9357\n",
            "Epoch [12/20], Loss: 72.1357\n",
            "Epoch [13/20], Loss: 69.4429\n",
            "Epoch [14/20], Loss: 66.6867\n",
            "Epoch [15/20], Loss: 63.9483\n",
            "Epoch [16/20], Loss: 61.3349\n",
            "Epoch [17/20], Loss: 58.5307\n",
            "Epoch [18/20], Loss: 55.7705\n",
            "Epoch [19/20], Loss: 53.3817\n",
            "Epoch [20/20], Loss: 50.6909\n",
            "\n",
            "[예측 테스트 결과]\n",
            "문맥(Context): ['마스크를', '벗었을때', '모습이']\n",
            "정답(Center): 썼을때와\n",
            "\n",
            "Top-5 예측 단어:\n",
            "1. 썼을때와 (확률: 0.0142)\n",
            "2. 벗었을때 (확률: 0.0033)\n",
            "3. 마스크를 (확률: 0.0032)\n",
            "4. 더럽다 (확률: 0.0031)\n",
            "5. 비슷함을 (확률: 0.0030)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 스타일 패턴 동일하게 실행(실패)"
      ],
      "metadata": {
        "id": "d-t2CiTfUFa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# 2. 데이터 불러오기\n",
        "df = pd.read_csv('/content/신조어_데이터셋_최종본_랜덤라벨링.csv')\n",
        "\n",
        "# 3. 번호 제거 함수\n",
        "def clean_word(word):\n",
        "    word = str(word)\n",
        "    return re.sub(r'^\\d+\\.', '', word).strip()\n",
        "\n",
        "# 4. 스타일 패턴 생성 함수 (숫자리듬 제거)\n",
        "def assign_style_in_code(word, desc):\n",
        "    styles = set()\n",
        "    if 2 <= len(word) <= 4:\n",
        "        styles.add('짧음')\n",
        "    if any(kw in word for kw in ['킹', '존', '갓', '빡', '철컹', '극', '찐', '꿀', '맛탱']):\n",
        "        styles.add('감정성')\n",
        "    if re.search(r'(..)\\1', word) or '봐' in word or '놈' in word:\n",
        "        styles.add('리듬감')\n",
        "    if any(kw in desc for kw in ['현실', '사바사', '복세편살', '편하게', '문화', '진상', '현생']):\n",
        "        styles.add('현실성')\n",
        "    if any(kw in desc for kw in ['웃긴', '밈', '웃음', '패러디', '유머', '개그']):\n",
        "        styles.add('유머성')\n",
        "    if any(kw in desc for kw in ['폭', '테러', '공격', '비하', '혐오']):\n",
        "        styles.add('과격성')\n",
        "    if not styles:\n",
        "        styles.add('짧음')\n",
        "    return ', '.join(styles)\n",
        "\n",
        "# 5. 신조어 클린 + 스타일 추가\n",
        "df['클린 신조어'] = df['신조어'].apply(clean_word)\n",
        "df['스타일 패턴'] = df.apply(lambda row: assign_style_in_code(row['클린 신조어'], row['설명']), axis=1)\n",
        "\n",
        "# 6. 간단 토크나이징\n",
        "def simple_tokenize(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", str(text))\n",
        "    tokens = text.strip().split()\n",
        "    tokens = [token for token in tokens if len(token) > 1]\n",
        "    return tokens\n",
        "\n",
        "# 7. 설명 토크나이징\n",
        "descriptions = df['설명'].tolist()\n",
        "tokenized_descriptions = [simple_tokenize(desc) for desc in descriptions]\n",
        "\n",
        "# 8. 어휘 사전 구축\n",
        "vocab = set()\n",
        "for tokens in tokenized_descriptions:\n",
        "    vocab.update(tokens)\n",
        "vocab = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 9. CBOW 학습용 데이터셋 생성\n",
        "window_size = 2\n",
        "context_center_pairs = []\n",
        "\n",
        "for tokens in tokenized_descriptions:\n",
        "    for idx, center_word in enumerate(tokens):\n",
        "        context = []\n",
        "        for i in range(idx - window_size, idx + window_size + 1):\n",
        "            if i != idx and 0 <= i < len(tokens):\n",
        "                context.append(vocab[tokens[i]])\n",
        "        if context:\n",
        "            context_center_pairs.append((context, vocab[center_word]))\n",
        "\n",
        "# 10. Dataset 클래스 정의\n",
        "class CBOWDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context, center = self.data[idx]\n",
        "        return torch.tensor(context), torch.tensor(center)\n",
        "\n",
        "# 11. DataLoader 생성\n",
        "dataset = CBOWDataset(context_center_pairs)\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=lambda batch: list(zip(*batch)))\n",
        "\n",
        "# 12. CBOW 모델 정의\n",
        "class CBOWModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100):\n",
        "        super(CBOWModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, contexts):\n",
        "        embeds = []\n",
        "        for context in contexts:\n",
        "            embed = self.embeddings(context)\n",
        "            embeds.append(embed.mean(dim=0))\n",
        "        embeds = torch.stack(embeds)\n",
        "        out = self.linear(embeds)\n",
        "        return out\n",
        "\n",
        "# 13. 모델 초기화\n",
        "model = CBOWModel(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 14. CBOW 모델 학습\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for contexts, centers in train_loader:\n",
        "        outputs = model(contexts)\n",
        "        loss = criterion(outputs, torch.tensor(centers))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "\n",
        "# 15. CBOW 문맥 예측 테스트\n",
        "model.eval()\n",
        "\n",
        "# 랜덤 context-center 하나 뽑기\n",
        "random_idx = random.randint(0, len(context_center_pairs) - 1)\n",
        "random_context, true_center = context_center_pairs[random_idx]\n",
        "\n",
        "# 예측 수행\n",
        "context_tensor = torch.tensor([random_context])\n",
        "predicted_logits = model(context_tensor)\n",
        "predicted_probs = F.softmax(predicted_logits, dim=1)\n",
        "top5 = torch.topk(predicted_probs, 5)\n",
        "\n",
        "print(\"\\n[CBOW 예측 테스트 결과]\")\n",
        "print(f\"문맥(Context): {[idx_to_word[idx] for idx in random_context]}\")\n",
        "print(f\"정답(Center): {idx_to_word[true_center]}\")\n",
        "\n",
        "print(\"\\nTop-5 예측 단어:\")\n",
        "for i in range(5):\n",
        "    idx = top5.indices[0][i].item()\n",
        "    prob = top5.values[0][i].item()\n",
        "    print(f\"{i+1}. {idx_to_word[idx]} (확률: {prob:.4f})\")\n",
        "\n",
        "# 16. 미래 신조어 예측 및 생성\n",
        "\n",
        "# 3개 랜덤 추출\n",
        "sample_rows = df.sample(3, random_state=random.randint(0,10000))\n",
        "\n",
        "print(\"\\n[미래 신조어 스타일 예측 및 새로운 신조어 생성]\")\n",
        "selected_words = []\n",
        "combined_styles = set()\n",
        "\n",
        "for idx, row in sample_rows.iterrows():\n",
        "    word = row['클린 신조어']\n",
        "    style = row['스타일 패턴']\n",
        "    print(f\"기존 신조어: {word}\")\n",
        "    print(f\"스타일 패턴: {style}\\n\")\n",
        "    selected_words.append(word)\n",
        "    combined_styles.update(style.split(', '))\n",
        "\n",
        "# 신조어 생성 (앞, 중간, 끝 조합)\n",
        "def safe_pick(word, pos):\n",
        "    if len(word) == 1:\n",
        "        return word\n",
        "    if pos == 'start':\n",
        "        return word[0]\n",
        "    elif pos == 'middle':\n",
        "        return word[len(word)//2]\n",
        "    elif pos == 'end':\n",
        "        return word[-1]\n",
        "    else:\n",
        "        return random.choice(word)\n",
        "\n",
        "new_created_word = (\n",
        "    safe_pick(selected_words[0], 'start') +\n",
        "    safe_pick(selected_words[1], 'middle') +\n",
        "    safe_pick(selected_words[2], 'end')\n",
        ")\n",
        "\n",
        "print(f\"👉 생성된 미래 신조어: {new_created_word}\")\n",
        "print(f\"👉 예상되는 스타일 패턴: {', '.join(list(combined_styles))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gVj6sSPS7ZY",
        "outputId": "d322a182-fc50-4604-f655-17974ada9620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 103.0230\n",
            "Epoch [2/20], Loss: 99.9260\n",
            "Epoch [3/20], Loss: 97.1296\n",
            "Epoch [4/20], Loss: 94.3229\n",
            "Epoch [5/20], Loss: 91.5756\n",
            "Epoch [6/20], Loss: 88.7025\n",
            "Epoch [7/20], Loss: 86.0574\n",
            "Epoch [8/20], Loss: 83.2617\n",
            "Epoch [9/20], Loss: 80.4505\n",
            "Epoch [10/20], Loss: 77.7155\n",
            "Epoch [11/20], Loss: 74.8336\n",
            "Epoch [12/20], Loss: 72.2546\n",
            "Epoch [13/20], Loss: 69.4565\n",
            "Epoch [14/20], Loss: 66.6130\n",
            "Epoch [15/20], Loss: 63.9407\n",
            "Epoch [16/20], Loss: 61.2313\n",
            "Epoch [17/20], Loss: 58.5000\n",
            "Epoch [18/20], Loss: 55.9597\n",
            "Epoch [19/20], Loss: 53.3505\n",
            "Epoch [20/20], Loss: 50.5186\n",
            "\n",
            "[CBOW 예측 테스트 결과]\n",
            "문맥(Context): ['닉네임']\n",
            "정답(Center): 차별\n",
            "\n",
            "Top-5 예측 단어:\n",
            "1. 차별 (확률: 0.0729)\n",
            "2. 너무 (확률: 0.0090)\n",
            "3. 젊은이들 (확률: 0.0066)\n",
            "4. 부담만 (확률: 0.0059)\n",
            "5. 기냥 (확률: 0.0053)\n",
            "\n",
            "[미래 신조어 스타일 예측 및 새로운 신조어 생성]\n",
            "기존 신조어: 빵프\n",
            "스타일 패턴: 짧음\n",
            "\n",
            "기존 신조어: 꾸에엑\n",
            "스타일 패턴: 짧음\n",
            "\n",
            "기존 신조어: 사바사\n",
            "스타일 패턴: 짧음\n",
            "\n",
            "👉 생성된 미래 신조어: 빵에사\n",
            "👉 예상되는 스타일 패턴: 짧음\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종본"
      ],
      "metadata": {
        "id": "INeVoyEfUPw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "df = pd.read_csv('/content/신조어_스타일_패턴_완성본_UTF8SIG.csv')\n",
        "\n",
        "# 2. 신조어 번호 제거 함수\n",
        "def clean_word(word):\n",
        "    word = str(word)\n",
        "    return re.sub(r'^\\d+\\.', '', word).strip()\n",
        "\n",
        "df['클린 신조어'] = df['신조어'].apply(clean_word)\n",
        "\n",
        "# 3. 랜덤 1개 신조어 뽑기\n",
        "first_sample = df.sample(1, random_state=random.randint(0,10000)).iloc[0]\n",
        "first_word = first_sample['클린 신조어']\n",
        "first_style = first_sample['스타일 패턴']\n",
        "\n",
        "print(f\"\\n[Step 1] 랜덤으로 뽑은 신조어\")\n",
        "print(f\"신조어: {first_word}\")\n",
        "print(f\"스타일 패턴: {first_style}\")\n",
        "\n",
        "# 4. 비슷한 스타일 패턴 가진 신조어 찾기\n",
        "# (부분 매칭 포함)\n",
        "similar_words_df = df[df['스타일 패턴'].str.contains(first_style.split(',')[0].strip())]\n",
        "\n",
        "# 첫 번째로 뽑은 단어는 제외\n",
        "similar_words_df = similar_words_df[similar_words_df['클린 신조어'] != first_word]\n",
        "\n",
        "# 5. 그 중 2개 랜덤으로 추가 추출\n",
        "additional_samples = similar_words_df.sample(2, random_state=random.randint(0,10000))\n",
        "\n",
        "selected_words = [first_word] + additional_samples['클린 신조어'].tolist()\n",
        "selected_styles = [first_style] + additional_samples['스타일 패턴'].tolist()\n",
        "\n",
        "print(f\"\\n[Step 2] 비슷한 스타일 패턴을 가진 추가 신조어 2개 뽑기\")\n",
        "for word, style in zip(selected_words[1:], selected_styles[1:]):\n",
        "    print(f\"신조어: {word}, 스타일 패턴: {style}\")\n",
        "\n",
        "# 6. 신조어 생성 로직\n",
        "def safe_pick(word, pos):\n",
        "    if len(word) == 1:\n",
        "        return word\n",
        "    if pos == 'start':\n",
        "        return word[0]\n",
        "    elif pos == 'middle':\n",
        "        return word[len(word)//2]\n",
        "    elif pos == 'end':\n",
        "        return word[-1]\n",
        "    else:\n",
        "        return random.choice(word)\n",
        "\n",
        "new_created_word = (\n",
        "    safe_pick(selected_words[0], 'start') +\n",
        "    safe_pick(selected_words[1], 'middle') +\n",
        "    safe_pick(selected_words[2], 'end')\n",
        ")\n",
        "\n",
        "# 7. 최종 출력\n",
        "print(f\"\\n[Step 3] 👉 3개 단어로 생성된 미래 신조어: {new_created_word}\")\n",
        "combined_styles = set()\n",
        "for style in selected_styles:\n",
        "    combined_styles.update(style.split(', '))\n",
        "print(f\"👉 예상되는 스타일 패턴: {', '.join(list(combined_styles))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMFdWWF-ClNl",
        "outputId": "c1380ce6-84ec-4f07-b9ae-1f39c6b30e96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Step 1] 랜덤으로 뽑은 신조어\n",
            "신조어: 핑프\n",
            "스타일 패턴: 음성적표현\n",
            "\n",
            "[Step 2] 비슷한 스타일 패턴을 가진 추가 신조어 2개 뽑기\n",
            "신조어: 얀데레, 스타일 패턴: 음성적표현\n",
            "신조어: 팩폭, 스타일 패턴: 음성적표현\n",
            "\n",
            "[Step 3] 👉 3개 단어로 생성된 미래 신조어: 핑데폭\n",
            "👉 예상되는 스타일 패턴: 음성적표현\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다음은 TF-IDF 유행 가능성 예측"
      ],
      "metadata": {
        "id": "Rl3dsZrzWy28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ TF-IDF 실험 초기화\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import re\n",
        "import random\n",
        "\n",
        "# 데이터 불러오기\n",
        "train_df = pd.read_csv('/content/신조어_데이터셋_유행.csv')\n",
        "predict_df = pd.read_csv('/content/신조어_데이터셋_예측.csv')"
      ],
      "metadata": {
        "id": "2dTQCfO2Wujf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ TF-IDF 데이터 정제\n",
        "\n",
        "def clean_word(word):\n",
        "    word = str(word)\n",
        "    return re.sub(r'^\\d+\\.', '', word).strip()\n",
        "\n",
        "train_df['클린 신조어'] = train_df['신조어'].apply(clean_word)\n",
        "predict_df['클린 신조어'] = predict_df['신조어'].apply(clean_word)"
      ],
      "metadata": {
        "id": "dlDymg86XlZZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ TF-IDF 벡터화\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=300)\n",
        "X_train = vectorizer.fit_transform(train_df['클린 신조어'].fillna(''))\n",
        "labels = train_df['유행여부']"
      ],
      "metadata": {
        "id": "z4OggBpnXz0H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 로지스틱 회귀 모델 학습\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "DupTZytwYBU9",
        "outputId": "9f7f32b0-2bb0-4bed-a52c-7adfd39c14ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 예측 데이터 벡터 변환\n",
        "\n",
        "X_predict = vectorizer.transform(predict_df['클린 신조어'].fillna(''))"
      ],
      "metadata": {
        "id": "NzydxjwkYQw0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 유행 여부 예측\n",
        "\n",
        "predict_preds = model.predict(X_predict)\n",
        "\n",
        "for word, pred in zip(predict_df['클린 신조어'], predict_preds):\n",
        "    print(f\"신조어: {word} -> 예측 결과: {'유행할 것' if pred == 1 else '비유행할 것'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCXggdYSYgCk",
        "outputId": "01a671f1-44e6-4da2-d9f9-a5227963664c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "신조어: 정누마 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친년 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친넘 -> 예측 결과: 비유행할 것\n",
            "신조어: 발컨 -> 예측 결과: 비유행할 것\n",
            "신조어: 억텐 -> 예측 결과: 비유행할 것\n",
            "신조어: 중꺽마 -> 예측 결과: 비유행할 것\n",
            "신조어: 갓생 -> 예측 결과: 비유행할 것\n",
            "신조어: 이선좌 -> 예측 결과: 비유행할 것\n",
            "신조어: 네카라쿠배당토 -> 예측 결과: 비유행할 것\n",
            "신조어: 막나귀 -> 예측 결과: 비유행할 것\n",
            "신조어: 섹시푸드 -> 예측 결과: 비유행할 것\n",
            "신조어: 가면비 -> 예측 결과: 비유행할 것\n",
            "신조어: 추구미 -> 예측 결과: 비유행할 것\n",
            "신조어: 안남미 -> 예측 결과: 비유행할 것\n",
            "신조어: 익속 -> 예측 결과: 비유행할 것\n",
            "신조어: 캘박 -> 예측 결과: 비유행할 것\n",
            "신조어: 분깨미 -> 예측 결과: 비유행할 것\n",
            "신조어: 돼지런 -> 예측 결과: 비유행할 것\n",
            "신조어: 꾸에엑 -> 예측 결과: 비유행할 것\n",
            "신조어: 감다살 -> 예측 결과: 비유행할 것\n",
            "신조어: 감다뒤 -> 예측 결과: 비유행할 것\n",
            "신조어: 종노플예 -> 예측 결과: 비유행할 것\n",
            "신조어: 싹싹 김치 -> 예측 결과: 비유행할 것\n",
            "신조어: 일세스코 -> 예측 결과: 비유행할 것\n",
            "신조어: 한플루언서 -> 예측 결과: 비유행할 것\n",
            "신조어: 위쑤시개 -> 예측 결과: 비유행할 것\n",
            "신조어: 밥플릭스 -> 예측 결과: 비유행할 것\n",
            "신조어: 랜선생님=랜선상님=랜선생=랜위인 -> 예측 결과: 비유행할 것\n",
            "신조어: 수발새끼 -> 예측 결과: 비유행할 것\n",
            "신조어: 수발년 -> 예측 결과: 비유행할 것\n",
            "신조어: 무지컬 -> 예측 결과: 비유행할 것\n",
            "신조어: 쌍무지컬 -> 예측 결과: 비유행할 것\n",
            "신조어: 손절미 -> 예측 결과: 비유행할 것\n",
            "신조어: 테무 인간 -> 예측 결과: 비유행할 것\n",
            "신조어: 느좋 -> 예측 결과: 비유행할 것\n",
            "신조어: 깊생 -> 예측 결과: 비유행할 것\n",
            "신조어: 세상이 날 억까해 -> 예측 결과: 비유행할 것\n",
            "신조어: 불소 -> 예측 결과: 유행할 것\n",
            "신조어: 반신 -> 예측 결과: 비유행할 것\n",
            "신조어: 반박 -> 예측 결과: 비유행할 것\n",
            "신조어: 윰차 -> 예측 결과: 비유행할 것\n",
            "신조어: 닉차 -> 예측 결과: 비유행할 것\n",
            "신조어: 설참 -> 예측 결과: 비유행할 것\n",
            "신조어: 전공 -> 예측 결과: 비유행할 것\n",
            "신조어: 싫테 -> 예측 결과: 비유행할 것\n",
            "신조어: 임구 -> 예측 결과: 비유행할 것\n",
            "신조어: 구취 -> 예측 결과: 비유행할 것\n",
            "신조어: 사바사 -> 예측 결과: 비유행할 것\n",
            "신조어: 꾸안꾸 -> 예측 결과: 비유행할 것\n",
            "신조어: 자만추 -> 예측 결과: 비유행할 것\n",
            "신조어: 핑프 -> 예측 결과: 비유행할 것\n",
            "신조어: 영고 -> 예측 결과: 유행할 것\n",
            "신조어: 별다줄 -> 예측 결과: 비유행할 것\n",
            "신조어: 오저치고 -> 예측 결과: 비유행할 것\n",
            "신조어: 만반잘부 -> 예측 결과: 비유행할 것\n",
            "신조어: 오놀아놈 -> 예측 결과: 비유행할 것\n",
            "신조어: 커엽 -> 예측 결과: 비유행할 것\n",
            "신조어: 존잘 -> 예측 결과: 비유행할 것\n",
            "신조어: 존예 -> 예측 결과: 비유행할 것\n",
            "신조어: 졸귀 -> 예측 결과: 비유행할 것\n",
            "신조어: tmi -> 예측 결과: 비유행할 것\n",
            "신조어: tmt -> 예측 결과: 비유행할 것\n",
            "신조어: 띵작 -> 예측 결과: 비유행할 것\n",
            "신조어: 씹상타 -> 예측 결과: 비유행할 것\n",
            "신조어: 팩폭 -> 예측 결과: 비유행할 것\n",
            "신조어: 레알 -> 예측 결과: 비유행할 것\n",
            "신조어: 철컹철컹 -> 예측 결과: 비유행할 것\n",
            "신조어: 와꾸,면상 -> 예측 결과: 비유행할 것\n",
            "신조어: 빼박캔트 -> 예측 결과: 비유행할 것\n",
            "신조어: ㅃㅂㅋㅌ ㅂㅂㅂㄱ -> 예측 결과: 비유행할 것\n",
            "신조어: 복세편살 -> 예측 결과: 비유행할 것\n",
            "신조어: 쌉소리 -> 예측 결과: 비유행할 것\n",
            "신조어: mukbang -> 예측 결과: 비유행할 것\n",
            "신조어: 삼귀다 -> 예측 결과: 비유행할 것\n",
            "신조어: 너 인성 문제 있어? -> 예측 결과: 비유행할 것\n",
            "신조어: 머리부터 발끝까지 -> 예측 결과: 비유행할 것\n",
            "신조어: 갑분싸 -> 예측 결과: 비유행할 것\n",
            "신조어: 머선129 -> 예측 결과: 비유행할 것\n",
            "신조어: 국룰 -> 예측 결과: 비유행할 것\n",
            "신조어: 자만추 -> 예측 결과: 비유행할 것\n",
            "신조어: asmr -> 예측 결과: 비유행할 것\n",
            "신조어: 레게노 -> 예측 결과: 비유행할 것\n",
            "신조어: jmt -> 예측 결과: 비유행할 것\n",
            "신조어: 존맛탱 -> 예측 결과: 비유행할 것\n",
            "신조어: 졸맛나 -> 예측 결과: 비유행할 것\n",
            "신조어: 말잇못 -> 예측 결과: 비유행할 것\n",
            "신조어: 문찐 -> 예측 결과: 비유행할 것\n",
            "신조어: 갑툭튀 -> 예측 결과: 비유행할 것\n",
            "신조어: 금사빠 -> 예측 결과: 비유행할 것\n",
            "신조어: 관종 -> 예측 결과: 비유행할 것\n",
            "신조어: 떡관종 -> 예측 결과: 비유행할 것\n",
            "신조어: 볼밉진 -> 예측 결과: 비유행할 것\n",
            "신조어: 댕댕이 -> 예측 결과: 비유행할 것\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 예측 결과 샘플링\n",
        "\n",
        "n_samples = 5\n",
        "sample_rows = predict_df.sample(n=n_samples, random_state=random.randint(0,10000))\n",
        "\n",
        "sample_texts = sample_rows['클린 신조어'].fillna('')\n",
        "sample_features = vectorizer.transform(sample_texts)\n",
        "sample_preds = model.predict(sample_features)\n",
        "\n",
        "print(\"\\n[미래 신조어 유행 여부 예측 결과]\\n\")\n",
        "for word, pred in zip(sample_rows['클린 신조어'], sample_preds):\n",
        "    print(f\"신조어: {word} -> 예측 결과: {'유행할 것' if pred == 1 else '비유행할 것'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOyRkztlZDU9",
        "outputId": "7f9ba40e-cbb6-4703-c6a7-6100fbc3dee7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[미래 신조어 유행 여부 예측 결과]\n",
            "\n",
            "신조어: 철컹철컹 -> 예측 결과: 비유행할 것\n",
            "신조어: 불소 -> 예측 결과: 유행할 것\n",
            "신조어: 머선129 -> 예측 결과: 비유행할 것\n",
            "신조어: 전공 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친년 -> 예측 결과: 비유행할 것\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 예측 확률 기반 임계값 설정 준비\n",
        "\n",
        "sample_probs = model.predict_proba(sample_features)\n",
        "\n",
        "threshold = 0.6  # 기본 0.5 → 0.6으로 실험\n",
        "for word, prob in zip(sample_rows['클린 신조어'], sample_probs):\n",
        "    prediction = 1 if prob[1] >= threshold else 0\n",
        "    print(f\"신조어: {word} -> 확률: {prob[1]:.4f} -> 예측 결과: {'유행할 것' if prediction == 1 else '비유행할 것'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHnDLorKZv14",
        "outputId": "d3ff4d62-0476-4ff6-e41b-76127c87855b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "신조어: 철컹철컹 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 불소 -> 확률: 0.5975 -> 예측 결과: 비유행할 것\n",
            "신조어: 머선129 -> 확률: 0.3996 -> 예측 결과: 비유행할 것\n",
            "신조어: 전공 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친년 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 다양한 임계값 테스트\n",
        "\n",
        "for threshold in [0.5, 0.6, 0.7]:\n",
        "    print(f\"\\n[임계값 {threshold} 적용 결과]\")\n",
        "    for word, prob in zip(sample_rows['클린 신조어'], sample_probs):\n",
        "        prediction = 1 if prob[1] >= threshold else 0\n",
        "        print(f\"신조어: {word} -> 확률: {prob[1]:.4f} -> 예측 결과: {'유행할 것' if prediction == 1 else '비유행할 것'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVrzoQzDaI8k",
        "outputId": "2b00bef7-df77-42fa-d6b9-02407a92e4a7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[임계값 0.5 적용 결과]\n",
            "신조어: 철컹철컹 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 불소 -> 확률: 0.5975 -> 예측 결과: 유행할 것\n",
            "신조어: 머선129 -> 확률: 0.3996 -> 예측 결과: 비유행할 것\n",
            "신조어: 전공 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친년 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "\n",
            "[임계값 0.6 적용 결과]\n",
            "신조어: 철컹철컹 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 불소 -> 확률: 0.5975 -> 예측 결과: 비유행할 것\n",
            "신조어: 머선129 -> 확률: 0.3996 -> 예측 결과: 비유행할 것\n",
            "신조어: 전공 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친년 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "\n",
            "[임계값 0.7 적용 결과]\n",
            "신조어: 철컹철컹 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 불소 -> 확률: 0.5975 -> 예측 결과: 비유행할 것\n",
            "신조어: 머선129 -> 확률: 0.3996 -> 예측 결과: 비유행할 것\n",
            "신조어: 전공 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n",
            "신조어: 미친년 -> 확률: 0.4982 -> 예측 결과: 비유행할 것\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 데이터 불균형 문제 발견\n",
        "# 유행 신조어 수가 훨씬 많아서 로지스틱 회귀가 1(유행할 것)로 편향될 가능성 있음\n",
        "# 향후 개선 방향: 언더샘플링, 오버샘플링, 또는 다른 모델 적용 고려"
      ],
      "metadata": {
        "id": "myat3wjNaYvI"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import re\n",
        "\n",
        "# 2. 데이터 불러오기\n",
        "df = pd.read_csv('/content/신조어_데이터셋_최종본_랜덤라벨링.csv')\n",
        "\n",
        "# 3. 신조어 번호 제거 (예: \"57.걍고\" -> \"걍고\")\n",
        "def clean_word(word):\n",
        "    word = str(word)\n",
        "    return re.sub(r'^\\d+\\.', '', word).strip()\n",
        "\n",
        "df['클린 신조어'] = df['신조어'].apply(clean_word)\n",
        "\n",
        "# 4. 텍스트 데이터와 레이블 준비\n",
        "texts = df['설명'].fillna('')  # 설명이 없으면 빈 문자열\n",
        "labels = df['유행여부']  # 0 or 1\n",
        "\n",
        "# 5. TF-IDF 벡터화\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # 최대 500개 단어로 제한\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# 6. 학습용 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 7. 로지스틱 회귀로 학습\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 8. 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n[TF-IDF + 로지스틱 회귀] 유행 여부 예측 정확도: {accuracy:.4f}\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"비유행(0)\", \"유행(1)\"]))\n",
        "\n",
        "# 9. 예시로 5개 문장에 대해 유행 여부 예측 출력\n",
        "sample_texts = df['설명'].sample(5, random_state=42)\n",
        "\n",
        "print(\"\\n[예시 5개 신조어 설명에 대한 유행 여부 예측]\")\n",
        "sample_features = vectorizer.transform(sample_texts)\n",
        "sample_preds = model.predict(sample_features)\n",
        "\n",
        "for text, pred in zip(sample_texts, sample_preds):\n",
        "    print(f\"설명: {text[:30]}... -> 예측: {'유행' if pred == 1 else '비유행'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hDdJ4aeeGsf",
        "outputId": "928ca0a8-d683-44e7-d9a6-20f129f8638c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TF-IDF + 로지스틱 회귀] 유행 여부 예측 정확도: 0.6364\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비유행(0)       0.65      0.27      0.38        41\n",
            "       유행(1)       0.63      0.90      0.74        58\n",
            "\n",
            "    accuracy                           0.64        99\n",
            "   macro avg       0.64      0.58      0.56        99\n",
            "weighted avg       0.64      0.64      0.59        99\n",
            "\n",
            "\n",
            "[예시 5개 신조어 설명에 대한 유행 여부 예측]\n",
            "설명: 만나서 반가워 잘 부탁해... -> 예측: 유행\n",
            "설명: 발로 컨트롤하다... -> 예측: 유행\n",
            "설명: 인터넷에 있는 사진 동영상 등의 자료가 삭제되었거나 경... -> 예측: 유행\n",
            "설명: 엄청나게 재미있음... -> 예측: 유행\n",
            "설명: 연인이 된지 22일 되는날.... -> 예측: 유행\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import re\n",
        "\n",
        "# 2. 데이터 불러오기\n",
        "df = pd.read_csv('/content/신조어_데이터셋_최종본_랜덤라벨링.csv')\n",
        "\n",
        "# 3. 데이터 전처리: 신조어 번호 제거\n",
        "def clean_word(word):\n",
        "    word = str(word)\n",
        "    return re.sub(r'^\\d+\\.', '', word).strip()\n",
        "\n",
        "df['클린 신조어'] = df['신조어'].apply(clean_word)\n",
        "\n",
        "# 4. Feature(설명 텍스트)와 Label(유행 여부) 준비\n",
        "texts = df['설명'].fillna('')  # 설명 없는 경우 빈 문자열로 대체\n",
        "labels = df['유행여부']\n",
        "\n",
        "# 5. 벡터화 시도: TF-IDF 선택 이유\n",
        "# 실험: CountVectorizer보다 TF-IDF가 빈도 중요도를 반영할 수 있어 정보량 손실을 줄일 수 있음\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # 최대 500개 단어로 제한\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# 6. 데이터 분할\n",
        "# 처음에는 random_state 고정해서 실험했지만, 매번 랜덤하게 성능 보는게 낫다고 판단 → random_state 제거\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2)\n",
        "\n",
        "# 7. 모델 선택: 로지스틱 회귀\n",
        "# 실험: 단순 선형 분류 문제이기 때문에 SVM보다는 빠르고 해석 가능한 Logistic Regression 선택\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 8. 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n[TF-IDF + 로지스틱 회귀] 유행 여부 예측 정확도: {accuracy:.4f}\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"비유행(0)\", \"유행(1)\"]))\n",
        "\n",
        "# 9. 예시 5개 문장 예측\n",
        "# 이전에는 random_state로 고정되었지만, 실험 다양성 확보를 위해 random_state 없이 random 샘플링 적용\n",
        "sample_texts = df['설명'].sample(5)\n",
        "\n",
        "print(\"\\n[예시 5개 신조어 설명에 대한 유행 여부 예측]\")\n",
        "sample_features = vectorizer.transform(sample_texts)\n",
        "sample_preds = model.predict(sample_features)\n",
        "\n",
        "for text, pred in zip(sample_texts, sample_preds):\n",
        "    print(f\"설명: {text[:30]}... -> 예측: {'유행' if pred == 1 else '비유행'}\")\n",
        "\n",
        "# 10. 성찰 및 개선점 코멘트\n",
        "print(\"\\n[성찰 및 개선점]\")\n",
        "print(\"- 현재 TF-IDF로 설명만 벡터화했는데, 설명이 짧거나 빈약한 경우 예측 성능이 떨어질 수 있음\")\n",
        "print(\"- 유행여부를 더 잘 맞추려면 '설명 + 스타일 패턴'을 feature로 함께 넣는 확장 시도가 가능함\")\n",
        "print(\"- 또는 신조어 자체를 subword 수준으로 분석해 특징을 추가하는 것도 가능\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCBx2FgWfjvC",
        "outputId": "2db75999-c02a-4b19-9978-510b95d37638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TF-IDF + 로지스틱 회귀] 유행 여부 예측 정확도: 0.5455\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      비유행(0)       0.48      0.23      0.31        44\n",
            "       유행(1)       0.56      0.80      0.66        55\n",
            "\n",
            "    accuracy                           0.55        99\n",
            "   macro avg       0.52      0.51      0.48        99\n",
            "weighted avg       0.53      0.55      0.50        99\n",
            "\n",
            "\n",
            "[예시 5개 신조어 설명에 대한 유행 여부 예측]\n",
            "설명: 미치도록 클릭... -> 예측: 유행\n",
            "설명: 얼굴 0점... -> 예측: 비유행\n",
            "설명: 자연스러운 만남을 추구... -> 예측: 비유행\n",
            "설명: 누구 물어본 사람?... -> 예측: 비유행\n",
            "설명: 무슨일이야?... -> 예측: 유행\n",
            "\n",
            "[성찰 및 개선점]\n",
            "- 현재 TF-IDF로 설명만 벡터화했는데, 설명이 짧거나 빈약한 경우 예측 성능이 떨어질 수 있음\n",
            "- 유행여부를 더 잘 맞추려면 '설명 + 스타일 패턴'을 feature로 함께 넣는 확장 시도가 가능함\n",
            "- 또는 신조어 자체를 subword 수준으로 분석해 특징을 추가하는 것도 가능\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 실험 결과 해석\n",
        "# - 임계값 조정에 따라 유행/비유행 분류가 다르게 나타남\n",
        "# - 기본 0.5 임계값이 가장 안정적이나, 유행 신조어 예측 Recall을 높이려면 0.6~0.7도 고려할 수 있음\n",
        "# - 향후: 신조어 자체 특징(길이, 음운, 감정성 등) feature 추가 시도해볼 것"
      ],
      "metadata": {
        "id": "nfA9xa0fa_n6"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}